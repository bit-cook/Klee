/**
 * useLocalChatLogic Hook
 *
 * Private Mode ‰∏ìÁî®ÁöÑËÅäÂ§©ÈÄªËæë
 *
 * ÁâπÁÇπÔºö
 * - ‰ΩøÁî® Ollama Êú¨Âú∞Ê®°ÂûãËøõË°åÂØπËØù
 * - ÈÄöËøá IPC ‰øùÂ≠òÊ∂àÊÅØÂà∞Êú¨Âú∞ SQLite
 * - ÊîØÊåÅÊµÅÂºèÂìçÂ∫î
 * - ÂÆåÂÖ®Á¶ªÁ∫øËøêË°å
 */

import { useState, useCallback, useEffect, useRef } from 'react'
import { useQueryClient } from '@tanstack/react-query'
import { generateUUID } from '@/lib/utils'
import { ollama, DEFAULT_MODEL } from '@/lib/ollama-client'
import { ipcAPI } from '@/lib/ipc-helpers'
import type { PromptInputMessage } from '@/components/ai-elements/prompt-input'
import type { LocalChatMessage } from '@/types'
import { streamText, type ChatStatus, type ModelMessage } from 'ai'

const parseIdList = (raw?: string): string[] => {
  if (!raw) return []
  try {
    const parsed = JSON.parse(raw)
    return Array.isArray(parsed) ? parsed.filter((item): item is string => typeof item === 'string') : []
  } catch {
    return []
  }
}

const areIdListsEqual = (a: string[], b: string[]) => {
  if (a.length !== b.length) return false
  const sortedA = [...a].sort()
  const sortedB = [...b].sort()
  return sortedA.every((value, index) => value === sortedB[index])
}

interface UseLocalChatLogicOptions {
  chatId?: string
  initialMessages?: LocalChatMessage[]
  initialModel?: string
  knowledgeBaseIds?: string[] // ÂÖ≥ËÅîÁöÑÁü•ËØÜÂ∫ì ID ÂàóË°®
  noteIds?: string[] // ÂÖ≥ËÅîÁöÑÁ¨îËÆ∞ ID ÂàóË°®
  onFinish?: () => void
}

/**
 * Private Mode ËÅäÂ§©ÈÄªËæë
 *
 * @example
 * ```tsx
 * const chat = useLocalChatLogic({
 *   chatId: 'some-uuid',
 *   initialModel: 'llama3:8b',
 *   onFinish: () => console.log('Message sent')
 * })
 *
 * // ÂèëÈÄÅÊ∂àÊÅØ
 * chat.handleSubmit({ text: 'Hello' })
 *
 * // Ê∏≤ÊüìÊ∂àÊÅØ
 * chat.messages.map(msg => <div>{msg.content}</div>)
 * ```
 */
export function useLocalChatLogic(options: UseLocalChatLogicOptions = {}) {
  const { chatId, initialMessages, initialModel, knowledgeBaseIds = [], noteIds = [], onFinish } = options

  const queryClient = useQueryClient()

  // Ê®°ÂûãÁä∂ÊÄÅ
  const [model, setModel] = useState<string>(initialModel ?? DEFAULT_MODEL)
  const [input, setInput] = useState('')
  const [status, setStatus] = useState<ChatStatus>('ready')
  const [messages, setMessages] = useState<LocalChatMessage[]>([])
  const [ragContext, setRagContext] = useState<string>('') // RAG Ê£ÄÁ¥¢‰∏ä‰∏ãÊñá
  const [isSearching, setIsSearching] = useState(false) // RAG Ê£ÄÁ¥¢Áä∂ÊÄÅ
  const abortControllerRef = useRef<AbortController | null>(null)

  // Â¶ÇÊûúÊèê‰æõ‰∫Ü initialMessages,‰ΩøÁî®ÂÆÉ‰ª¨;Âê¶Âàô‰ªé IPC Âä†ËΩΩ
  useEffect(() => {
    if (initialMessages && initialMessages.length > 0) {
      // ‰ΩøÁî®Êèê‰æõÁöÑÂàùÂßãÊ∂àÊÅØ
      const formatted = initialMessages.map((msg) => ({
        id: msg.id,
        role: msg.role,
        content: msg.content,
        createdAt: msg.createdAt,
      }))
      setMessages(formatted)
    } else if (chatId) {
      // ‰ªé IPC Âä†ËΩΩÊ∂àÊÅØ
      ipcAPI
        .getMessages(chatId)
        .then((dbMessages) => {
          const formatted = dbMessages.map((msg) => ({
            id: msg.id,
            role: msg.role as 'user' | 'assistant',
            content: JSON.parse(msg.parts)[0]?.text || '',
            createdAt: typeof msg.createdAt === 'number' ? new Date(msg.createdAt) : msg.createdAt,
          }))
          setMessages(formatted)
        })
        .catch((error) => {
          console.error('[Local Chat] Failed to load messages:', error)
        })
    }
  }, [chatId, initialMessages])

  const stop = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort()
      abortControllerRef.current = null
      setStatus('ready')
    }
  }, [])

  // Âä†ËΩΩ‰ºöËØùÂÖÉÊï∞ÊçÆÔºàÊ®°ÂûãÁ≠âÔºâÔºåÁî®‰∫éÂú®ÈáçÊñ∞ËøõÂÖ•ËÅäÂ§©Êó∂ÊÅ¢Â§çÈÖçÁΩÆ
  useEffect(() => {
    if (!chatId) return

    ipcAPI
      .getConversation(chatId)
      .then((conversation) => {
        if (conversation?.model) {
          setModel(conversation.model)
        }
      })
      .catch((error) => {
        console.error('[Local Chat] Failed to load conversation metadata:', error)
      })
  }, [chatId])

  const buildMessagesForAI = useCallback(
    (chatMessages: LocalChatMessage[], ragContext?: string): ModelMessage[] => {
      const baseMessages = chatMessages.map((msg) => ({
        role: msg.role,
        content: msg.content,
      })) as ModelMessage[]

      console.log('[Local Chat RAG] üîß Building messages for AI...')
      console.log('[Local Chat RAG] üí¨ Base messages count:', baseMessages.length)
      console.log('[Local Chat RAG] üìö RAG context provided:', ragContext ? 'YES' : 'NO')

      // Â¶ÇÊûúÊúâ RAG ‰∏ä‰∏ãÊñá,Â∞ÜÂÖ∂Ê≥®ÂÖ•‰∏∫Á≥ªÁªüÊ∂àÊÅØ
      if (ragContext && baseMessages.length > 0) {
        const systemContent = `You have access to the following information from the knowledge base. Use it to answer the user's questions when relevant:\n\n${ragContext}`
        const systemMessage = {
          role: 'system',
          content: systemContent,
        } as ModelMessage

        console.log('[Local Chat RAG] ‚úÖ Injecting RAG context as system message')
        console.log('[Local Chat RAG] üìè System message length:', systemContent.length, 'chars')
        console.log('[Local Chat RAG] üéØ System message preview:', systemContent.substring(0, 300) + '...')

        const finalMessages = [systemMessage, ...baseMessages]
        console.log('[Local Chat RAG] üì§ Final messages to send to Ollama:', finalMessages.length)
        console.log('[Local Chat RAG] üóÇÔ∏è Final messages structure:', finalMessages.map(m => ({
          role: m.role,
          contentType: typeof m.content,
          contentLength: typeof m.content === 'string' ? m.content.length : 'N/A'
        })))

        return finalMessages
      }

      console.log('[Local Chat RAG] ‚ÑπÔ∏è No RAG context, sending messages as-is')
      return baseMessages
    },
    []
  )

  /**
   * ÂèëÈÄÅÊ∂àÊÅØÂà∞Êú¨Âú∞ Ollama
   */
  const handleSubmit = useCallback(
    async (message: PromptInputMessage) => {
      if (!message.text?.trim()) return

      setInput('')
      setStatus('submitted')

      // 0. Á°Æ‰øùËÅäÂ§©‰ºöËØùÂ≠òÂú®ÔºàÊñ∞‰ºöËØùÊó∂ÂàõÂª∫Ôºâ
      if (!chatId) {
        console.error('[Local Chat] No chat ID provided')
        setStatus('ready')
        return
      }

      // Âä®ÊÄÅËé∑ÂèñÊúÄÊñ∞ÁöÑÁü•ËØÜÂ∫ì IDs ÂíåÁ¨îËÆ∞ IDs (‰ªé options ‰∏≠Ëé∑ÂèñÊúÄÊñ∞ÂÄº)
      const currentKnowledgeBaseIds = options.knowledgeBaseIds || []
      const currentNoteIds = options.noteIds || []
      console.log('[Local Chat RAG] üîÑ Current knowledge base IDs at submit time:', currentKnowledgeBaseIds)
      console.log('[Local Chat RAG] üîÑ Current note IDs at submit time:', currentNoteIds)

      // Ê£ÄÊü•‰ºöËØùÊòØÂê¶Â≠òÂú®ÔºåÂ¶ÇÊûú‰∏çÂ≠òÂú®ÂàôÂàõÂª∫
      // ‰ΩøÁî®Êú¨Âú∞ÂèòÈáèÂ≠òÂÇ®ÂΩìÂâçÂ∫îËØ•‰ΩøÁî®ÁöÑÊ®°ÂûãÔºåÈÅøÂÖçÁä∂ÊÄÅÊõ¥Êñ∞Âª∂Ëøü
      const currentModel = model && model.trim().length > 0 ? model : DEFAULT_MODEL

      try {
        const existingConversation = await ipcAPI.getConversation(chatId)
        const updates: {
          model?: string
          availableKnowledgeBaseIds?: string[]
          availableNoteIds?: string[]
        } = {}

        if (!existingConversation) {
          await ipcAPI.createConversation({
            id: chatId,
            title: message.text.slice(0, 50) + (message.text.length > 50 ? '...' : ''),
            model: currentModel,
          })

          if (currentKnowledgeBaseIds.length > 0) {
            updates.availableKnowledgeBaseIds = currentKnowledgeBaseIds
          }

          if (currentNoteIds.length > 0) {
            updates.availableNoteIds = currentNoteIds
          }
        } else {
          const storedKbIds = parseIdList(existingConversation.availableKnowledgeBaseIds)
          const storedNoteIds = parseIdList(existingConversation.availableNoteIds)

          if (existingConversation.model !== currentModel) {
            updates.model = currentModel
          }

          if (!areIdListsEqual(storedKbIds, currentKnowledgeBaseIds)) {
            updates.availableKnowledgeBaseIds = currentKnowledgeBaseIds
          }

          if (!areIdListsEqual(storedNoteIds, currentNoteIds)) {
            updates.availableNoteIds = currentNoteIds
          }
        }

        if (Object.keys(updates).length > 0) {
          try {
            await ipcAPI.updateConversation(chatId, updates)
          } catch (error) {
            console.error('[Local Chat] Failed to persist conversation configuration:', error)
          }
        }

        setModel(currentModel)
      } catch (error) {
        console.error('[Local Chat] Failed to ensure conversation exists:', error)
      }

      // 1. Ê∑ªÂä†Áî®Êà∑Ê∂àÊÅØ
      const userMessageId = generateUUID()
      const userMessage = {
        id: userMessageId,
        role: 'user' as const,
        content: message.text,
        createdAt: new Date(),
      }

      // ‰øùÂ≠òÁî®Êà∑Ê∂àÊÅØÂà∞Êú¨Âú∞Êï∞ÊçÆÂ∫ì
      try {
        await ipcAPI.createMessage({
          id: userMessageId,
          chatId,
          role: 'user',
          parts: JSON.stringify([{ type: 'text', text: message.text }]),
          attachments: '[]',
        })
      } catch (error) {
        console.error('[Local Chat] Failed to save user message:', error)
      }

      // Ê∑ªÂä†Âà∞ UI
      setMessages((prev) => [...prev, userMessage])

      // 2. Â¶ÇÊûúÂÖ≥ËÅî‰∫ÜÁü•ËØÜÂ∫ìÊàñÁ¨îËÆ∞,ÊâßË°å RAG Ê£ÄÁ¥¢
      console.log('[Local Chat RAG] üéØ Checking knowledge base IDs before search:', currentKnowledgeBaseIds)
      console.log('[Local Chat RAG] üéØ Knowledge base IDs length:', currentKnowledgeBaseIds.length)
      console.log('[Local Chat RAG] üéØ Checking note IDs before search:', currentNoteIds)
      console.log('[Local Chat RAG] üéØ Note IDs length:', currentNoteIds.length)

      let kbContext = ''
      let noteContext = ''

      // 2a. ÊêúÁ¥¢Áü•ËØÜÂ∫ì
      if (currentKnowledgeBaseIds.length > 0) {
        console.log('[Local Chat RAG] üîç Starting search with knowledge bases:', currentKnowledgeBaseIds)
        console.log('[Local Chat RAG] üìù User query:', message.text)

        try {
          setIsSearching(true)
          const searchResult = await window.api.knowledgeBase.search(
            message.text,
            currentKnowledgeBaseIds,
            5
          )

          console.log('[Local Chat RAG] üì¶ KB search result received:', searchResult)

          // Ê£ÄÊü• IPC ÂìçÂ∫îÊòØÂê¶ÊàêÂäü (Ê†ºÂºè: { success: true, data: { results: [...] } })
          if ('success' in searchResult && searchResult.success && searchResult.data) {
            console.log('[Local Chat RAG] üîé KB search result data:', searchResult.data)
            const results = searchResult.data.results as any[]

            console.log('[Local Chat RAG] üìä Found KB results:', results ? results.length : 0)

            if (results && results.length > 0) {
              // Ê†ºÂºèÂåñÊ£ÄÁ¥¢ÁªìÊûú
              kbContext = results
                .map(
                  (result, index) => {
                    console.log(`[Local Chat RAG] üìÑ KB Result ${index + 1}:`, {
                      fileName: result.fileName,
                      similarity: result.similarity.toFixed(3),
                      contentPreview: result.content.substring(0, 100) + '...'
                    })
                    return `[Document ${index + 1}] (from ${result.fileName})\n${result.content}\n`
                  }
                )
                .join('\n')

              console.log('[Local Chat RAG] ‚úÖ KB context prepared, total length:', kbContext.length, 'chars')
            } else {
              console.log('[Local Chat RAG] ‚ö†Ô∏è No KB results found for query')
            }
          }
        } catch (error) {
          console.error('[Local Chat RAG] ‚ùå KB search failed:', error)
          // Ê£ÄÁ¥¢Â§±Ë¥•‰∏çÂ∫îÈòªÊ≠¢ËÅäÂ§©,ÁªßÁª≠ÊâßË°å
        } finally {
          setIsSearching(false)
        }
      } else {
        console.log('[Local Chat RAG] ‚ÑπÔ∏è No knowledge bases associated with this chat')
      }

      // 2b. ÊêúÁ¥¢Á¨îËÆ∞
      if (currentNoteIds.length > 0) {
        console.log('[Local Chat RAG] üìù Starting search with notes:', currentNoteIds)
        console.log('[Local Chat RAG] üìù User query:', message.text)

        try {
          setIsSearching(true)
          const searchResult = await window.api.note.search({
            query: message.text,
            noteIds: currentNoteIds,
            limit: 5
          })

          console.log('[Local Chat RAG] üì¶ Note search result received:', searchResult)

          // Ê£ÄÊü• IPC ÂìçÂ∫îÊòØÂê¶ÊàêÂäü
          if ('success' in searchResult && searchResult.success && searchResult.data) {
            console.log('[Local Chat RAG] üîé Note search result data:', searchResult.data)
            const results = searchResult.data as any[]

            console.log('[Local Chat RAG] üìä Found note results:', results ? results.length : 0)

            if (results && results.length > 0) {
              // Ê†ºÂºèÂåñÁ¨îËÆ∞Ê£ÄÁ¥¢ÁªìÊûú
              noteContext = results
                .map(
                  (result, index) => {
                    console.log(`[Local Chat RAG] üìù Note Result ${index + 1}:`, {
                      sourceName: result.sourceName,
                      similarity: result.similarity.toFixed(3),
                      contentPreview: result.content.substring(0, 100) + '...'
                    })
                    return `[Note ${index + 1}] (from "${result.sourceName}")\n${result.content}\n`
                  }
                )
                .join('\n')

              console.log('[Local Chat RAG] ‚úÖ Note context prepared, total length:', noteContext.length, 'chars')
            } else {
              console.log('[Local Chat RAG] ‚ö†Ô∏è No note results found for query')
            }
          }
        } catch (error) {
          console.error('[Local Chat RAG] ‚ùå Note search failed:', error)
          // Ê£ÄÁ¥¢Â§±Ë¥•‰∏çÂ∫îÈòªÊ≠¢ËÅäÂ§©,ÁªßÁª≠ÊâßË°å
        } finally {
          setIsSearching(false)
        }
      } else {
        console.log('[Local Chat RAG] ‚ÑπÔ∏è No notes associated with this chat')
      }

      // 2c. ÂêàÂπ∂Áü•ËØÜÂ∫ìÂíåÁ¨îËÆ∞ÁöÑÊêúÁ¥¢ÁªìÊûú
      let searchContext = ''
      if (kbContext && noteContext) {
        searchContext = `Knowledge Base Documents:\n\n${kbContext}\n\nNotes:\n\n${noteContext}`
      } else if (kbContext) {
        searchContext = kbContext
      } else if (noteContext) {
        searchContext = noteContext
      }

      if (searchContext) {
        setRagContext(searchContext)
        console.log('[Local Chat RAG] ‚úÖ Combined RAG context prepared, total length:', searchContext.length, 'chars')
        console.log('[Local Chat RAG] üìã Context preview:', searchContext.substring(0, 200) + '...')
      }

      console.log('[Local Chat RAG] üìã Search context final result:', searchContext ? `${searchContext.length} chars` : 'EMPTY')

      // 3. ÂáÜÂ§áÊ∂àÊÅØÂéÜÂè≤ (Ê≥®ÂÖ• RAG ‰∏ä‰∏ãÊñá)
      const messagesForAI = buildMessagesForAI([...messages, userMessage], searchContext)
      console.log('[Local Chat RAG] üé¨ Ready to send to Ollama, messages count:', messagesForAI.length)

      // 3. Ë∞ÉÁî® Ollama ÊµÅÂºèÁîüÊàê
      const assistantMessageId = generateUUID()
      let fullResponse = ''
      const assistantMessage: LocalChatMessage = {
        id: assistantMessageId,
        role: 'assistant',
        content: '',
        createdAt: new Date(),
      }

      try {
        // ÂàõÂª∫Âç†‰ΩçÁ¨¶Âä©ÊâãÊ∂àÊÅØ
        setMessages((prev) => [...prev, assistantMessage])
        setStatus('streaming')

        // ‰∏∫ÂΩìÂâçËØ∑Ê±ÇÂàõÂª∫Êñ∞ÁöÑ AbortController
        abortControllerRef.current?.abort()
        const abortController = new AbortController()
        abortControllerRef.current = abortController

        // ÊµÅÂºèÁîüÊàêÔºà‰ΩøÁî® AI SDK streamTextÔºâ
        const result = await streamText({
          model: ollama(currentModel),
          messages: messagesForAI,
          abortSignal: abortController.signal,
        })

        // Â§ÑÁêÜÊµÅÂºèÂìçÂ∫î
        for await (const textPart of result.textStream) {
          if (abortController.signal.aborted) break

          fullResponse += textPart

          // Êõ¥Êñ∞ UI ‰∏≠ÁöÑÂä©ÊâãÊ∂àÊÅØ
          setMessages((prev) =>
            prev.map((m) => (m.id === assistantMessageId ? { ...m, content: fullResponse } : m))
          )
        }

        // 4. ‰øùÂ≠òÂä©ÊâãÊ∂àÊÅØÂà∞Êú¨Âú∞Êï∞ÊçÆÂ∫ì
        await ipcAPI.createMessage({
          id: assistantMessageId,
          chatId,
          role: 'assistant',
          parts: JSON.stringify([{ type: 'text', text: fullResponse }]),
          attachments: '[]',
        })

        // 5. Â§±ÊïàÁºìÂ≠ò
        queryClient.invalidateQueries(['local-conversations'])
        queryClient.invalidateQueries(['local-messages', chatId])

        setStatus('ready')
        abortControllerRef.current = null
        onFinish?.()
      } catch (error) {
        if ((error as Error)?.name === 'AbortError') {
          setStatus('ready')
          return
        }

        console.error('[Local Chat] Ollama error:', error)
        setStatus('error')
        abortControllerRef.current = null

        // ÊòæÁ§∫ÈîôËØØÊ∂àÊÅØ
        setMessages((prev) =>
          prev.map((m) =>
            m.id === assistantMessageId
              ? {
                  ...m,
                  content:
                    'Error: Failed to get response from Ollama. Please make sure Ollama is running.',
                }
              : m
          )
        )

        throw error
      }
    },
    [messages, model, chatId, setMessages, queryClient, onFinish, buildMessagesForAI, options]
  )

  /**
   * Âà†Èô§Ê∂àÊÅØ
   */
  const handleDelete = useCallback(
    async (messageId: string) => {
      try {
        // ‰ªéÊï∞ÊçÆÂ∫ìÂà†Èô§
        await ipcAPI.deleteMessage(messageId)

        // ‰ªé UI Âà†Èô§
        setMessages((prev) => prev.filter((m) => m.id !== messageId))

        // Â§±ÊïàÁºìÂ≠ò
        queryClient.invalidateQueries(['local-messages', chatId])
      } catch (error) {
        console.error('[Local Chat] Failed to delete message:', error)
      }
    },
    [chatId, setMessages, queryClient]
  )

  /**
   * ÈáçÊñ∞ÁîüÊàêÊúÄÂêé‰∏ÄÊù°Âä©ÊâãÊ∂àÊÅØ
   */
  const handleRegenerate = useCallback(
    async (messageId: string) => {
      if (!chatId) {
        console.error('[Local Chat] No chat ID provided for regeneration')
        return
      }

      // ÊâæÂà∞Ë¶ÅÈáçÊñ∞ÁîüÊàêÁöÑÊ∂àÊÅØÁöÑÁ¥¢Âºï
      const messageIndex = messages.findIndex((m) => m.id === messageId)
      if (messageIndex === -1 || messages[messageIndex].role !== 'assistant') {
        console.error('[Local Chat] Invalid message for regeneration')
        return
      }

      setStatus('submitted')

      // Ëé∑ÂèñËØ•Ê∂àÊÅØ‰πãÂâçÁöÑÊâÄÊúâÊ∂àÊÅØÔºàÁî®‰∫é‰∏ä‰∏ãÊñáÔºâ
      const contextMessages = messages.slice(0, messageIndex)

      // Âà†Èô§ÊóßÁöÑÂä©ÊâãÊ∂àÊÅØ
      await handleDelete(messageId)

      // ÂáÜÂ§áÊ∂àÊÅØÂéÜÂè≤
      // ÁîüÊàêÊñ∞ÁöÑÂìçÂ∫î
      const newAssistantMessageId = generateUUID()
      let fullResponse = ''
      const assistantMessage: LocalChatMessage = {
        id: newAssistantMessageId,
        role: 'assistant',
        content: '',
        createdAt: new Date(),
      }

      try {
        setMessages((prev) => [...prev, assistantMessage])
        setStatus('streaming')

        abortControllerRef.current?.abort()
        const abortController = new AbortController()
        abortControllerRef.current = abortController

        const result = await streamText({
          model: ollama(model),
          messages: buildMessagesForAI(contextMessages),
          abortSignal: abortController.signal,
        })

        for await (const textPart of result.textStream) {
          if (abortController.signal.aborted) break

          fullResponse += textPart

          setMessages((prev) =>
            prev.map((m) => (m.id === newAssistantMessageId ? { ...m, content: fullResponse } : m))
          )
        }

        // ‰øùÂ≠òÊñ∞Ê∂àÊÅØ
        try {
          await ipcAPI.createMessage({
            id: newAssistantMessageId,
            chatId,
            role: 'assistant',
            parts: JSON.stringify([{ type: 'text', text: fullResponse }]),
            attachments: '[]',
          })
        } catch (error) {
          console.error('[Local Chat] Failed to save regenerated assistant message:', error)
        }

        queryClient.invalidateQueries(['local-messages', chatId])

        setStatus('ready')
        abortControllerRef.current = null
        onFinish?.()
      } catch (error) {
        if ((error as Error)?.name === 'AbortError') {
          setStatus('ready')
          return
        }

        console.error('[Local Chat] Regenerate error:', error)
        setStatus('error')
        abortControllerRef.current = null
        throw error
      }
    },
    [messages, model, chatId, handleDelete, queryClient, onFinish, buildMessagesForAI]
  )

  return {
    input,
    setInput,
    model,
    setModel,
    messages,
    status,
    handleSubmit,
    handleDelete,
    handleRegenerate,
    stop,
    chatId,
    ragContext,
    isSearching,
  }
}

export type { LocalChatMessage }
