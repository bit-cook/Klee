# Quick Start: Private Mode å¼€å‘æŒ‡å—

**Feature**: 006-private-mode
**ç”Ÿæˆæ—¥æœŸ**: 2025-10-20
**ç›®æ ‡è¯»è€…**: å¼€å‘è€…ï¼ˆé¦–æ¬¡æ¥è§¦æœ¬åŠŸèƒ½ï¼‰

---

## æ¦‚è¿°

Private Mode å…è®¸ç”¨æˆ·åœ¨å®Œå…¨ç¦»çº¿çš„ç¯å¢ƒä¸‹ä½¿ç”¨ Rafaï¼Œæ‰€æœ‰æ•°æ®ï¼ˆå¯¹è¯ã€çŸ¥è¯†åº“ï¼‰å­˜å‚¨åœ¨æœ¬åœ°ï¼Œæ— ä»»ä½•äº‘ç«¯äº¤äº’ã€‚

**æ ¸å¿ƒæŠ€æœ¯æ ˆ**:
- Electronï¼ˆæ¡Œé¢åº”ç”¨æ¡†æ¶ï¼‰
- Ollamaï¼ˆæœ¬åœ° LLM æ¨ç†ï¼‰
- LanceDBï¼ˆæœ¬åœ°å‘é‡æ•°æ®åº“ï¼‰
- SQLiteï¼ˆæœ¬åœ°å…³ç³»æ•°æ®åº“ï¼‰
- Vercel AI SDKï¼ˆæµå¼å¯¹è¯ï¼‰

---

## å¼€å‘ç¯å¢ƒè®¾ç½®

### 1. å®‰è£…ä¾èµ–

```bash
cd /Users/wei/Coding/rafa/client

# Ollama é›†æˆ
npm install electron-ollama ollama

# å‘é‡æ•°æ®åº“
npm install vectordb @lancedb/lancedb

# æœ¬åœ°æ•°æ®åº“
npm install better-sqlite3 drizzle-orm
npm install -D drizzle-kit drizzle-zod

# æµ‹è¯•å·¥å…·
npm install -D @playwright/test electron-playwright-helpers
npm install -D vitest @vitest/ui jsdom
npm install -D @testing-library/react @testing-library/jest-dom
```

### 2. é…ç½® Drizzle ORM

```bash
# ç”Ÿæˆ SQLite schema
npx drizzle-kit generate:sqlite --schema=./db/schema-local.ts

# è¿è¡Œè¿ç§»
npx drizzle-kit push:sqlite
```

### 3. å¯åŠ¨ Ollamaï¼ˆæœ¬åœ°æµ‹è¯•ï¼‰

```bash
# macOS
brew install ollama
ollama serve

# ä¸‹è½½æµ‹è¯•æ¨¡å‹
ollama pull llama3:8b
ollama pull nomic-embed-text  # åµŒå…¥æ¨¡å‹
```

---

## é¡¹ç›®ç»“æ„å¯¼èˆª

```
client/
â”œâ”€â”€ electron/                    # Electron ä¸»è¿›ç¨‹
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â””â”€â”€ index.ts             # ä¸»å…¥å£ï¼ˆåˆå§‹åŒ– Ollama + DBï¼‰
â”‚   â”œâ”€â”€ services/                # æ ¸å¿ƒæœåŠ¡
â”‚   â”‚   â”œâ”€â”€ ollama-manager.ts    # Ollama ç”Ÿå‘½å‘¨æœŸç®¡ç†
â”‚   â”‚   â”œâ”€â”€ vector-db-manager.ts # LanceDB ç®¡ç†
â”‚   â”‚   â””â”€â”€ db-connection.ts     # SQLite è¿æ¥ç®¡ç†
â”‚   â””â”€â”€ ipc/                     # IPC å¤„ç†å™¨
â”‚       â”œâ”€â”€ ollama-handlers.ts
â”‚       â”œâ”€â”€ vector-handlers.ts
â”‚       â””â”€â”€ db-handlers.ts
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ contexts/
â”‚   â”‚   â””â”€â”€ ModeContext.tsx      # è¿è¡Œæ¨¡å¼ä¸Šä¸‹æ–‡
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ mode/
â”‚   â”‚   â”‚   â”œâ”€â”€ useMode.ts       # æ¨¡å¼åˆ‡æ¢ Hook
â”‚   â”‚   â”‚   â””â”€â”€ useModeSync.ts   # æ¨¡å¼çŠ¶æ€åŒæ­¥
â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â””â”€â”€ useLocalChat.ts  # æœ¬åœ°èŠå¤© Hookï¼ˆæ–°å¢ï¼‰
â”‚   â”‚   â””â”€â”€ knowledge-base/
â”‚   â”‚       â””â”€â”€ useLocalKB.ts    # æœ¬åœ°çŸ¥è¯†åº“ Hookï¼ˆæ–°å¢ï¼‰
â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ local-utils/         # æœ¬åœ°å·¥å…·å‡½æ•°
â”‚           â”œâ”€â”€ embedding.ts
â”‚           â””â”€â”€ vector-search.ts
â””â”€â”€ db/
    â””â”€â”€ schema-local.ts          # SQLite schema å®šä¹‰
```

---

## æ ¸å¿ƒå¼€å‘æµç¨‹

### Step 1: æ¨¡å¼åˆ‡æ¢å®ç°

```typescript
// src/contexts/ModeContext.tsx
import { createContext, useState, useEffect } from 'react'

export const ModeContext = createContext<{
  mode: 'cloud' | 'private'
  setMode: (mode: 'cloud' | 'private') => void
  isPrivateMode: boolean
} | null>(null)

export function ModeProvider({ children }) {
  const [mode, setModeState] = useState<'cloud' | 'private'>('cloud')

  const setMode = (newMode) => {
    setModeState(newMode)
    localStorage.setItem('run-mode', newMode)
    window.electron.ipcRenderer.send('mode:switch', { mode: newMode })
  }

  useEffect(() => {
    const saved = localStorage.getItem('run-mode') || 'cloud'
    setModeState(saved as any)
  }, [])

  return (
    <ModeContext.Provider value={{ mode, setMode, isPrivateMode: mode === 'private' }}>
      {children}
    </ModeContext.Provider>
  )
}
```

### Step 2: Ollama æœåŠ¡ç®¡ç†ï¼ˆæ™ºèƒ½æ£€æµ‹ç‰ˆæœ¬ï¼‰

```typescript
// electron/services/ollama-manager.ts
import { ElectronOllama } from 'electron-ollama'
import { app } from 'electron'
import path from 'path'

type OllamaSource = 'system' | 'embedded' | 'none'

export class OllamaManager {
  private ollama: ElectronOllama | null = null
  private ollamaSource: OllamaSource = 'none'
  private readonly basePath: string

  constructor() {
    this.basePath = path.join(app.getPath('userData'), 'ollama')
  }

  async initialize() {
    // 1. ä¼˜å…ˆæ£€æµ‹ç³»ç»Ÿ Ollama
    const systemOllamaAvailable = await this.detectSystemOllama()

    if (systemOllamaAvailable) {
      this.ollamaSource = 'system'
      console.log('âœ… Using system Ollama')
      return { source: 'system' as const, url: 'http://localhost:11434' }
    }

    // 2. ç³»ç»Ÿæ—  Ollamaï¼Œä½¿ç”¨å†…åµŒç‰ˆæœ¬
    console.log('â¬‡ï¸ Downloading embedded Ollama...')
    this.ollamaSource = 'embedded'

    this.ollama = new ElectronOllama({ basePath: this.basePath })

    if (!(await this.ollama.isRunning())) {
      const metadata = await this.ollama.getMetadata('latest')
      await this.ollama.serve(metadata.version, {
        serverLog: (msg) => console.log('[Ollama]', msg),
        downloadLog: (percent, msg) => console.log(`[Download] ${percent}%: ${msg}`)
      })
    }

    return { source: 'embedded' as const, url: 'http://localhost:11434' }
  }

  private async detectSystemOllama(): Promise<boolean> {
    try {
      const controller = new AbortController()
      const timeoutId = setTimeout(() => controller.abort(), 2000)

      const response = await fetch('http://localhost:11434/api/tags', {
        method: 'GET',
        signal: controller.signal
      })

      clearTimeout(timeoutId)

      if (response.ok) {
        const data = await response.json()
        return 'models' in data
      }
      return false
    } catch {
      return false
    }
  }

  getSource(): OllamaSource {
    return this.ollamaSource
  }

  async shutdown() {
    // ä»…å…³é—­å†…åµŒ Ollamaï¼Œä¸å½±å“ç³»ç»Ÿ Ollama
    if (this.ollamaSource === 'system') {
      console.log('â„¹ï¸ Using system Ollama, skipping shutdown')
      return
    }

    if (this.ollamaSource !== 'embedded') return

    const { exec } = require('child_process')
    const ollamaPath = path.join(this.basePath, 'bin', 'ollama')

    try {
      if (process.platform === 'darwin' || process.platform === 'linux') {
        exec(`pkill -f "${ollamaPath}"`)
      } else {
        // Windows: é€šè¿‡è·¯å¾„è¿‡æ»¤è¿›ç¨‹
        exec(`wmic process where "ExecutablePath='${ollamaPath.replace(/\\/g, '\\\\')}'" delete`)
      }
    } catch {
      console.log('â„¹ï¸ Ollama already terminated')
    }
  }
}
```

### Step 3: æœ¬åœ°èŠå¤©å®ç°

```typescript
// src/hooks/chat/useLocalChat.ts
import { useState } from 'react'
import { useMode } from '@/contexts/ModeContext'

export function useLocalChat(conversationId: string) {
  const { isPrivateMode } = useMode()
  const [messages, setMessages] = useState([])
  const [isLoading, setIsLoading] = useState(false)

  const sendMessage = async (content: string) => {
    if (!isPrivateMode) {
      throw new Error('useLocalChat can only be used in Private Mode')
    }

    setIsLoading(true)

    // è°ƒç”¨ Electron IPC
    window.electron.ipcRenderer.on('ollama:chat-stream', (data) => {
      if (data.conversationId === conversationId) {
        setMessages(prev => {
          const last = prev[prev.length - 1]
          if (last?.role === 'assistant') {
            return [...prev.slice(0, -1), { ...last, content: last.content + data.delta }]
          }
          return [...prev, { role: 'assistant', content: data.delta }]
        })
      }
    })

    const result = await window.electron.ipcRenderer.invoke('ollama:chat', {
      model: 'llama3:8b',
      messages: [...messages, { role: 'user', content }],
      conversationId
    })

    setIsLoading(false)

    if (!result.success) {
      throw new Error(result.error)
    }
  }

  return { messages, sendMessage, isLoading }
}
```

### Step 4: çŸ¥è¯†åº“å‘é‡åŒ–

```typescript
// src/hooks/knowledge-base/useLocalKB.ts
export function useLocalKBEmbedding(kbId: string) {
  const [progress, setProgress] = useState(0)

  const embedDocuments = async (files: File[]) => {
    // ç›‘å¬å‘é‡åŒ–è¿›åº¦
    window.electron.ipcRenderer.on('vector:embed-progress', (data) => {
      if (data.knowledgeBaseId === kbId) {
        setProgress((data.current / data.total) * 100)
      }
    })

    const documents = files.map(file => ({
      id: crypto.randomUUID(),
      text: await file.text(),
      metadata: { fileName: file.name }
    }))

    const result = await window.electron.ipcRenderer.invoke('vector:embed-documents', {
      knowledgeBaseId: kbId,
      documents
    })

    if (!result.success) {
      throw new Error(result.error)
    }

    return result.count
  }

  const searchSimilar = async (query: string) => {
    const result = await window.electron.ipcRenderer.invoke('vector:search', {
      knowledgeBaseId: kbId,
      query,
      limit: 10
    })

    if (!result.success) {
      throw new Error(result.error)
    }

    return result.results
  }

  return { embedDocuments, searchSimilar, progress }
}
```

---

## æµ‹è¯•æŒ‡å—

### å•å…ƒæµ‹è¯•ï¼ˆVitestï¼‰

```bash
# è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•
npm run test

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
npm run test useLocalChat.test.ts

# æŸ¥çœ‹æµ‹è¯•è¦†ç›–ç‡
npm run test:coverage
```

ç¤ºä¾‹æµ‹è¯•ï¼š
```typescript
// src/hooks/chat/useLocalChat.test.ts
import { renderHook, waitFor } from '@testing-library/react'
import { describe, it, expect, vi } from 'vitest'
import { useLocalChat } from './useLocalChat'

describe('useLocalChat', () => {
  it('should send message to Ollama', async () => {
    const { result } = renderHook(() => useLocalChat('test-conversation'))

    await result.current.sendMessage('Hello')

    await waitFor(() => {
      expect(result.current.messages).toHaveLength(2)
      expect(result.current.messages[0].role).toBe('user')
      expect(result.current.messages[1].role).toBe('assistant')
    })
  })
})
```

### E2E æµ‹è¯•ï¼ˆPlaywrightï¼‰

```bash
# è¿è¡Œ E2E æµ‹è¯•
npm run test:e2e

# è°ƒè¯•æ¨¡å¼
npm run test:e2e:debug

# æœ‰å¤´æ¨¡å¼ï¼ˆæŸ¥çœ‹ UIï¼‰
npm run test:e2e:headed
```

ç¤ºä¾‹æµ‹è¯•ï¼š
```typescript
// e2e/private-mode.spec.ts
import { test, expect } from './fixtures/electron'

test('should work completely offline', async ({ page }) => {
  // åˆ‡æ¢åˆ° Private Mode
  await page.click('[data-testid="private-mode-toggle"]')

  // éªŒè¯æ¨¡å¼æŒ‡ç¤ºå™¨
  await expect(page.locator('[data-testid="private-mode-indicator"]')).toBeVisible()

  // å‘é€æ¶ˆæ¯
  await page.fill('[data-testid="chat-input"]', 'Test offline')
  await page.click('[data-testid="send-button"]')

  // éªŒè¯å“åº”
  await expect(page.locator('[data-testid="chat-message"]').last()).toContainText('Test offline')
})
```

---

## è°ƒè¯•æŠ€å·§

### 1. æŸ¥çœ‹ Electron ä¸»è¿›ç¨‹æ—¥å¿—

```bash
# æ‰“å¼€ DevTools æŸ¥çœ‹ä¸»è¿›ç¨‹æ—¥å¿—
npm run dev

# ä¸»è¿›ç¨‹æ—¥å¿—ä¼šæ˜¾ç¤ºåœ¨ç»ˆç«¯
# æ¸²æŸ“è¿›ç¨‹æ—¥å¿—åœ¨æµè§ˆå™¨ DevTools ä¸­
```

### 2. æ£€æŸ¥ Ollama çŠ¶æ€

```bash
# æŸ¥çœ‹ Ollama æ˜¯å¦è¿è¡Œ
curl http://localhost:11434/api/tags

# æŸ¥çœ‹å·²ä¸‹è½½æ¨¡å‹
ollama list
```

### 3. æ£€æŸ¥ SQLite æ•°æ®åº“

```bash
# ä½¿ç”¨ sqlite3 å‘½ä»¤è¡Œå·¥å…·
sqlite3 ~/Library/Application\ Support/Rafa/rafa-private.db

# æŸ¥çœ‹è¡¨
.tables

# æŸ¥è¯¢æ•°æ®
SELECT * FROM conversations;
```

### 4. æ£€æŸ¥ LanceDB æ•°æ®

```bash
# æŸ¥çœ‹å‘é‡æ•°æ®åº“ç›®å½•
ls -lh ~/Library/Application\ Support/Rafa/vector-db/

# æŸ¥çœ‹ç‰¹å®šçŸ¥è¯†åº“çš„å‘é‡è¡¨
# (éœ€è¦é€šè¿‡ä»£ç æˆ– Python è„šæœ¬æŸ¥çœ‹)
```

---

## å¸¸è§é—®é¢˜

### Q: Ollama ä¸‹è½½å¡ä½æˆ–å¤±è´¥

**A**: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–æ‰‹åŠ¨ä¸‹è½½ Ollama äºŒè¿›åˆ¶æ–‡ä»¶ï¼š
```bash
# macOS
curl -O https://ollama.com/download/ollama-darwin
```

### Q: å‘é‡åŒ–é€Ÿåº¦å¾ˆæ…¢

**A**: æ£€æŸ¥ä»¥ä¸‹å› ç´ ï¼š
1. ä½¿ç”¨ SSD è€Œé HDD
2. å‡å°‘æ–‡æ¡£å¤§å°æˆ–åˆ†å—å¤§å°
3. ä½¿ç”¨æ›´å¿«çš„åµŒå…¥æ¨¡å‹

### Q: æ¨¡å¼åˆ‡æ¢åæ•°æ®ä¸¢å¤±

**A**: è¿™æ˜¯æ­£å¸¸çš„ï¼Cloud/Private æ•°æ®å®Œå…¨éš”ç¦»ã€‚å¦‚éœ€è¿ç§»æ•°æ®ï¼Œä½¿ç”¨å¯¼å‡º/å¯¼å…¥åŠŸèƒ½ï¼ˆæœªæ¥åŠŸèƒ½ï¼‰ã€‚

### Q: æµ‹è¯•æ—¶æ— æ³•è¿æ¥ Ollama

**A**: ç¡®ä¿æµ‹è¯•ç¯å¢ƒä¸­ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œï¼š
```bash
# å¯åŠ¨ Ollamaï¼ˆæµ‹è¯•å‰ï¼‰
ollama serve &
```

---

## ä¸‹ä¸€æ­¥

1. âœ… å®ŒæˆåŸºç¡€è®¾ç½®
2. â­ï¸ é˜…è¯» [data-model.md](./data-model.md) äº†è§£æ•°æ®ç»“æ„
3. â­ï¸ æŸ¥çœ‹ [contracts/ipc-channels.md](./contracts/ipc-channels.md) äº†è§£ IPC API
4. â­ï¸ è¿è¡Œ `/speckit.tasks` ç”Ÿæˆå…·ä½“å¼€å‘ä»»åŠ¡

---

## æœ‰ç”¨çš„å‘½ä»¤

```bash
# å¼€å‘
npm run dev                    # å¯åŠ¨å¼€å‘æœåŠ¡å™¨

# æµ‹è¯•
npm run test                   # å•å…ƒæµ‹è¯•
npm run test:e2e               # E2E æµ‹è¯•
npm run test:coverage          # æµ‹è¯•è¦†ç›–ç‡

# æ„å»º
npm run build                  # æ„å»ºç”Ÿäº§ç‰ˆæœ¬
npm run package                # æ‰“åŒ… Electron åº”ç”¨

# æ•°æ®åº“
npx drizzle-kit studio         # æŸ¥çœ‹æ•°æ®åº“ï¼ˆå¯è§†åŒ–ï¼‰
npx drizzle-kit generate       # ç”Ÿæˆè¿ç§»æ–‡ä»¶
npx drizzle-kit push           # åº”ç”¨è¿ç§»

# Ollama
ollama list                    # åˆ—å‡ºå·²å®‰è£…æ¨¡å‹
ollama pull <model>            # ä¸‹è½½æ¨¡å‹
ollama rm <model>              # åˆ é™¤æ¨¡å‹
```

---

## èµ„æºé“¾æ¥

- Electron æ–‡æ¡£: https://www.electronjs.org/docs
- Ollama æ–‡æ¡£: https://ollama.com/docs
- LanceDB æ–‡æ¡£: https://lancedb.github.io/lancedb/
- Vercel AI SDK: https://sdk.vercel.ai/docs
- Playwright Electron: https://playwright.dev/docs/api/class-electron

ç¥å¼€å‘é¡ºåˆ©ï¼ğŸš€
