# Research Report: Marketplace Private Mode - æŠ€æœ¯ç ”ç©¶ä¸å†³ç­–

**Date**: 2025-10-23
**Feature**: Marketplace Private Mode - æœ¬åœ°å¼€æºå¤§æ¨¡å‹ç®¡ç†
**Status**: Phase 0 Complete

## æ‰§è¡Œæ‘˜è¦

æœ¬ç ”ç©¶æŠ¥å‘Šä¸º Marketplace Private Mode åŠŸèƒ½æä¾›å®Œæ•´çš„æŠ€æœ¯å†³ç­–ä¾æ®ï¼Œæ¶µç›– Ollama API é›†æˆã€TanStack Query æµå¼ä¸‹è½½ã€ç£ç›˜ç©ºé—´æ£€æµ‹å’Œæ¨¡å‹åˆ é™¤å®‰å…¨æ€§ã€‚æ‰€æœ‰ç ”ç©¶ä»»åŠ¡å·²å®Œæˆï¼Œå…³é”®å†³ç­–å·²æ˜ç¡®ã€‚

---

## 1. Ollama API é›†æˆç ”ç©¶

### 1.1 å·²éªŒè¯çš„ API ç«¯ç‚¹

#### `/api/tags` - åˆ—å‡ºå·²å®‰è£…æ¨¡å‹

**è¯·æ±‚**:
\`\`\`bash
GET http://localhost:11434/api/tags
\`\`\`

**å“åº”**:
\`\`\`json
{
  "models": [
    {
      "name": "llama3:8b",
      "model": "llama3:8b",
      "modified_at": "2024-05-15T10:30:00Z",
      "size": 4661224320,
      "digest": "sha256:1234567890abcdef",
      "details": {
        "parent_model": "",
        "format": "gguf",
        "family": "llama",
        "families": ["llama"],
        "parameter_size": "8B",
        "quantization_level": "Q4_0"
      }
    }
  ]
}
\`\`\`

**é¡¹ç›®ä¸­ç°æœ‰å®ç°**:
\`\`\`typescript
// client/src/renderer/src/lib/ollama-client.ts
export async function getInstalledModels() {
  const response = await fetch('http://localhost:11434/api/tags')
  const data = await response.json()
  return data.models || []
}
\`\`\`

#### `/api/pull` - ä¸‹è½½æ¨¡å‹ï¼ˆNDJSON æµå¼å“åº”ï¼‰

**è¯·æ±‚**:
\`\`\`bash
POST http://localhost:11434/api/pull
Content-Type: application/json

{
  "name": "llama3:8b",
  "stream": true
}
\`\`\`

**å“åº”ï¼ˆNDJSON æµï¼‰**:
\`\`\`json
{"status":"pulling manifest"}
{"status":"downloading digestname","digest":"sha256:abc123","total":4661224320,"completed":1048576}
{"status":"downloading digestname","digest":"sha256:abc123","total":4661224320,"completed":10485760}
...
{"status":"verifying sha256 digest"}
{"status":"writing manifest"}
{"status":"removing any unused layers"}
{"status":"success"}
\`\`\`

**å…³é”®å­—æ®µ**:
- `status`: å½“å‰çŠ¶æ€ï¼ˆ`pulling manifest` / `downloading digestname` / `verifying sha256 digest` / `writing manifest` / `success`ï¼‰
- `total`: æ€»å­—èŠ‚æ•°
- `completed`: å·²ä¸‹è½½å­—èŠ‚æ•°
- `digest`: å½“å‰ä¸‹è½½çš„ blob SHA256

#### `/api/delete` - åˆ é™¤æ¨¡å‹

**è¯·æ±‚**:
\`\`\`bash
DELETE http://localhost:11434/api/delete
Content-Type: application/json

{
  "name": "llama3:8b"
}
\`\`\`

**æˆåŠŸå“åº”**:
\`\`\`json
{}
\`\`\`

**é”™è¯¯å“åº”**:
\`\`\`json
{
  "error": "model 'llama3:8b' is in use"
}
\`\`\`

**Ollama JS SDK (v0.6.0)**:
\`\`\`typescript
import { Ollama } from 'ollama'

const ollama = new Ollama({ host: 'http://localhost:11434' })

// åˆ é™¤æ¨¡å‹
await ollama.delete({ model: 'llama3:8b' })
\`\`\`

### 1.2 æš‚åœ/ç»§ç»­ä¸‹è½½æœºåˆ¶

**ç ”ç©¶ç»“è®º**: Ollama API **ä¸æ”¯æŒ** HTTP Range Requestsï¼Œå› æ­¤ï¼š

âŒ **æ— æ³•å®ç°çœŸæ­£çš„æš‚åœ/ç»§ç»­**ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
âœ… **å¯ä»¥å®ç°å–æ¶ˆåé‡æ–°å¼€å§‹**

**æ¨èæ–¹æ¡ˆ**: ä½¿ç”¨ AbortController å–æ¶ˆä¸‹è½½ï¼ŒUI æ˜¾ç¤º"æš‚åœ"æŒ‰é’®å®é™…æ‰§è¡Œå–æ¶ˆæ“ä½œã€‚

**å®ç°ç¤ºä¾‹**:
\`\`\`typescript
const controller = new AbortController()

fetch('http://localhost:11434/api/pull', {
  method: 'POST',
  body: JSON.stringify({ name: modelName, stream: true }),
  signal: controller.signal,
})

// ç”¨æˆ·ç‚¹å‡»"æš‚åœ"
controller.abort() // å–æ¶ˆä¸‹è½½

// ç”¨æˆ·ç‚¹å‡»"ç»§ç»­"
// é‡æ–°å¼€å§‹ä¸‹è½½ï¼ˆä»å¤´å¼€å§‹ï¼Œéæ–­ç‚¹ç»­ä¼ ï¼‰
\`\`\`

**ç”¨æˆ·ä½“éªŒä¼˜åŒ–**:
- UI æ–‡æ¡ˆæ˜ç¡®è¯´æ˜ï¼š"Pausing will cancel the download. Continue will restart from the beginning."
- æ˜¾ç¤ºè­¦å‘Šï¼šå¤§æ–‡ä»¶ä¸‹è½½å»ºè®®ä¸€æ¬¡å®Œæˆ

### 1.3 é‡å¤ä¸‹è½½æ£€æµ‹æœºåˆ¶

**æ–¹æ¡ˆ**: åœ¨ä¸‹è½½å‰æŸ¥è¯¢ `/api/tags`ï¼Œè¿‡æ»¤å·²å®‰è£…çš„æ¨¡å‹ã€‚

**å®ç°**:
\`\`\`typescript
// 1. è·å–å·²å®‰è£…æ¨¡å‹åˆ—è¡¨
const installedModels = await getInstalledModels()
const installedModelNames = new Set(installedModels.map(m => m.name))

// 2. è¿‡æ»¤é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹åˆ—è¡¨
const availableModels = localLLMModels.filter(
  model => !installedModelNames.has(model.model)
)

// 3. åœ¨ UI ä¸­æ˜¾ç¤º"å·²å®‰è£…"çŠ¶æ€
const modelStatus = installedModelNames.has(model.model) 
  ? 'installed' 
  : 'available'
\`\`\`

**å…³é”®ç‚¹**:
- electron-ollama å’Œç³»ç»Ÿ Ollama å…±äº«ç›¸åŒçš„æ¨¡å‹å­˜å‚¨è·¯å¾„ï¼ˆ`~/.ollama/models`ï¼‰ï¼Œå› æ­¤ `/api/tags` ä¼šè¿”å›æ‰€æœ‰å·²å®‰è£…æ¨¡å‹
- æ— éœ€é¢å¤–æ£€æµ‹é€»è¾‘ï¼Œç›´æ¥æŸ¥è¯¢ API å³å¯

---

## 2. TanStack Query æµå¼ä¸‹è½½é›†æˆ

### 2.1 æ ¸å¿ƒæ–¹æ¡ˆï¼šuseMutation + React State

**ç»“è®º**: TanStack Query v4 çš„ `useMutation` ä¸æ”¯æŒæµå¼æ•°æ®ï¼Œå¿…é¡»ç»“åˆ React State å®ç°å®æ—¶è¿›åº¦æ›´æ–°ã€‚

**å®Œæ•´å®ç°**:
\`\`\`typescript
import { useMutation } from '@tanstack/react-query'
import { useState, useCallback, useRef } from 'react'

export function useDownloadOllamaModel() {
  const [progress, setProgress] = useState<OllamaDownloadProgress | null>(null)
  const abortControllerRef = useRef<AbortController | null>(null)

  const mutation = useMutation({
    mutationFn: async (modelName: string) => {
      const controller = new AbortController()
      abortControllerRef.current = controller

      try {
        await pullOllamaModel(
          modelName,
          (p) => setProgress(p), // å®æ—¶æ›´æ–°è¿›åº¦
          controller.signal
        )
      } finally {
        abortControllerRef.current = null
      }
    },

    onSuccess: () => {
      setProgress({ status: 'success', percent: 100 })
    },

    onError: () => {
      setProgress(null)
    },
  })

  const cancel = useCallback(() => {
    abortControllerRef.current?.abort()
    setProgress(null)
  }, [])

  return {
    download: mutation.mutate,
    isDownloading: mutation.isLoading,
    progress,
    cancel,
  }
}
\`\`\`

### 2.2 NDJSON æµå¼è§£æ

**å®ç°**:
\`\`\`typescript
async function pullOllamaModel(
  modelName: string,
  onProgress: (progress: OllamaDownloadProgress) => void,
  signal?: AbortSignal
): Promise<void> {
  const response = await fetch('http://localhost:11434/api/pull', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ name: modelName, stream: true }),
    signal,
  })

  const reader = response.body?.getReader()
  const decoder = new TextDecoder()
  let buffer = ''

  while (true) {
    const { done, value } = await reader.read()
    if (done) break

    buffer += decoder.decode(value, { stream: true })
    const lines = buffer.split('\n')
    buffer = lines.pop() || ''

    for (const line of lines) {
      if (!line.trim()) continue
      const data = JSON.parse(line)

      onProgress({
        status: data.status,
        completed: data.completed || 0,
        total: data.total || 0,
        percent: data.total ? Math.round((data.completed / data.total) * 100) : 0,
      })
    }
  }
}
\`\`\`

### 2.3 å¹¶å‘ä¸‹è½½é™åˆ¶

**æ¨èæ–¹æ¡ˆ**: ä½¿ç”¨ `p-queue` åº“ï¼ˆæœ€å¤š 2 ä¸ªå¹¶å‘ï¼‰

**å®‰è£…**:
\`\`\`bash
npm install p-queue
\`\`\`

**å®ç°**:
\`\`\`typescript
import PQueue from 'p-queue'

const downloadQueue = new PQueue({ concurrency: 2 })

export function useOllamaDownloadQueue() {
  const mutation = useMutation({
    mutationFn: async (modelName: string) => {
      await downloadQueue.add(async () => {
        await pullOllamaModel(modelName, onProgress, signal)
      })
    },
  })

  return {
    download: mutation.mutate,
    activeCount: downloadQueue.pending,
    queueSize: downloadQueue.size,
  }
}
\`\`\`

**å¤‡é€‰æ–¹æ¡ˆ**: è‡ªå®šä¹‰é˜Ÿåˆ—ï¼ˆæ— å¤–éƒ¨ä¾èµ–ï¼‰

\`\`\`typescript
class DownloadQueue {
  private queue: Array<() => Promise<void>> = []
  private running = 0
  private readonly concurrency: number

  constructor(concurrency: number) {
    this.concurrency = concurrency
  }

  async add(fn: () => Promise<void>): Promise<void> {
    return new Promise((resolve, reject) => {
      const task = async () => {
        try {
          await fn()
          resolve()
        } catch (error) {
          reject(error)
        } finally {
          this.running--
          this.process()
        }
      }

      this.queue.push(task)
      this.process()
    })
  }

  private process() {
    while (this.running < this.concurrency && this.queue.length > 0) {
      const task = this.queue.shift()
      if (task) {
        this.running++
        task()
      }
    }
  }
}
\`\`\`

**å†³ç­–**: ä½¿ç”¨ `p-queue`ï¼ˆæˆç†Ÿã€å¯é ã€ç¤¾åŒºéªŒè¯ï¼‰

---

## 3. ç£ç›˜ç©ºé—´æ£€æµ‹

### 3.1 æ¨èæ–¹æ¡ˆï¼šNode.js åŸç”Ÿ API

**é¡¹ç›®ç¯å¢ƒ**: Node.js v22.14.0ï¼Œå®Œå…¨æ”¯æŒ `fs.statfs()` APIï¼ˆv19.6+ å¯ç”¨ï¼‰

**å®ç°ï¼ˆä¸»è¿›ç¨‹ï¼‰**:
\`\`\`typescript
import { statfsSync } from 'fs'
import { app } from 'electron'

export function getOllamaDiskSpace() {
  const ollamaPath = path.join(app.getPath('userData'), 'ollama', 'models')
  const stats = statfsSync(ollamaPath)

  const totalBytes = stats.blocks * stats.bsize
  const freeBytes = stats.bfree * stats.bsize
  const availableBytes = stats.bavail * stats.bsize

  return {
    totalBytes,
    freeBytes,
    availableBytes,
    usedBytes: totalBytes - freeBytes,
    percentUsed: ((totalBytes - freeBytes) / totalBytes) * 100,
  }
}
\`\`\`

**IPC é›†æˆ**:
\`\`\`typescript
// ä¸»è¿›ç¨‹
ipcMain.handle('disk-space:get', async () => {
  return { success: true, data: getOllamaDiskSpace() }
})

// å‰ç«¯
const { data: diskSpace } = useQuery({
  queryKey: ['disk-space', 'ollama'],
  queryFn: async () => {
    const result = await window.api.diskSpace.get()
    return result.data
  },
  staleTime: 30 * 1000,
  refetchInterval: 60 * 1000,
})
\`\`\`

### 3.2 ä¸‹è½½å‰ç£ç›˜æ£€æŸ¥

**å®ç°**:
\`\`\`typescript
export function useDownloadOllamaModel() {
  const { data: diskSpace } = useDiskSpace()

  const mutation = useMutation({
    mutationFn: async (model: { name: string; size: number }) => {
      // æ£€æŸ¥ç£ç›˜ç©ºé—´ï¼ˆç•™ 1GB ç¼“å†²ï¼‰
      const requiredSpace = model.size + 1024 * 1024 * 1024
      
      if (diskSpace && diskSpace.availableBytes < requiredSpace) {
        throw new Error(
          \`Insufficient disk space. Required: \${formatBytes(requiredSpace)}, Available: \${diskSpace.availableFormatted}\`
        )
      }

      await pullOllamaModel(model.name, onProgress, signal)
    },

    onError: (error) => {
      if (error.message.includes('Insufficient disk space')) {
        toast.error('Not enough disk space', {
          description: error.message,
        })
      }
    },
  })
}
\`\`\`

---

## 4. æ¨¡å‹åˆ é™¤å®‰å…¨æ€§

### 4.1 æ¨¡å‹ä½¿ç”¨æ£€æµ‹

**æ•°æ®æº**: SQLite æœ¬åœ°æ•°æ®åº“ï¼ˆPrivate Modeï¼‰

**Schema**:
\`\`\`typescript
// client/src/main/local/db/schema.ts
export const localChatSessions = sqliteTable('chat_sessions', {
  id: text('id').primaryKey(),
  model: text('model').notNull(), // ğŸ‘ˆ æ¨¡å‹ ID
  // ... å…¶ä»–å­—æ®µ
})
\`\`\`

**æŸ¥è¯¢å®ç°**:
\`\`\`typescript
// client/src/main/local/db/queries/models.ts
export async function isModelInUse(
  db: ReturnType<typeof drizzle>,
  modelId: string
): Promise<boolean> {
  const sessions = await db
    .select({ id: localChatSessions.id })
    .from(localChatSessions)
    .where(eq(localChatSessions.model, modelId))
    .limit(1)
  
  return sessions.length > 0
}
\`\`\`

**IPC å¤„ç†å™¨**:
\`\`\`typescript
ipcMain.handle('model:check-in-use', async (event, modelId: string) => {
  const db = dbManager.getDb()
  const inUse = await isModelInUse(db, modelId)
  return { success: true, data: { inUse } }
})
\`\`\`

### 4.2 å®‰å…¨åˆ é™¤æµç¨‹

**å®Œæ•´æµç¨‹**:
\`\`\`typescript
// ä¸»è¿›ç¨‹
export async function deleteModel(
  modelId: string,
  force: boolean = false
): Promise<ModelDeleteResult> {
  // 1. æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¢«ä½¿ç”¨
  if (!force) {
    const db = dbManager.getDb()
    const inUse = await isModelInUse(db, modelId)
    
    if (inUse) {
      const sessions = await getSessionsUsingModel(db, modelId)
      return {
        success: false,
        reason: 'in_use',
        error: \`Model is used by \${sessions.length} session(s)\`,
        sessionsUsingModel: sessions,
      }
    }
  }
  
  // 2. è°ƒç”¨ Ollama API åˆ é™¤
  try {
    await ollama.delete({ model: modelId })
    return { success: true }
  } catch (error) {
    // 3. è§£æé”™è¯¯
    if (error.message.includes('model is in use')) {
      return {
        success: false,
        reason: 'in_use',
        error: 'Model is currently running in Ollama',
      }
    }
    throw error
  }
}
\`\`\`

**å‰ç«¯ Mutation**:
\`\`\`typescript
export function useDeleteModel() {
  return useMutation({
    mutationFn: async ({ modelId }: { modelId: string }) => {
      const result = await window.api.model.delete(modelId)
      
      if (!result.success) {
        throw new Error(JSON.stringify(result.data))
      }
      
      return result.data
    },
    
    onError: (error) => {
      const errorData = JSON.parse(error.message)
      
      if (errorData.reason === 'in_use') {
        toast.error('Cannot delete model', {
          description: \`Used by \${errorData.sessionsUsingModel.length} session(s)\`,
        })
      }
    },
    
    onSuccess: () => {
      queryClient.invalidateQueries(['local-models'])
      queryClient.invalidateQueries(['disk-space'])
    },
  })
}
\`\`\`

### 4.3 Ollama åˆ é™¤è¡Œä¸º

**æ™ºèƒ½å±‚ç®¡ç†**:
- Ollama ä½¿ç”¨ **å†…å®¹å¯»å€å­˜å‚¨**ï¼ˆContent-Addressable Storageï¼‰
- å¤šä¸ªæ¨¡å‹å¯ä»¥å…±äº«ç›¸åŒçš„ blobï¼ˆå¦‚åŸºç¡€å±‚ï¼‰
- åˆ é™¤æ¨¡å‹åªä¼šåˆ é™¤è¯¥æ¨¡å‹ç‹¬æœ‰çš„ blob
- å…±äº« blob åœ¨æ‰€æœ‰å¼•ç”¨æ¨¡å‹éƒ½è¢«åˆ é™¤åæ‰ä¼šåˆ é™¤

**ç¤ºä¾‹**:
\`\`\`bash
# llama3:8b å’Œ llama3:70b å…±äº«åŸºç¡€å±‚ï¼ˆ3.7GBï¼‰
# llama3:8b ç‹¬æœ‰å±‚ï¼š1GB
# llama3:70b ç‹¬æœ‰å±‚ï¼š36GB

ollama rm llama3:8b
# åªé‡Šæ”¾ 1GB ç©ºé—´ï¼ˆç‹¬æœ‰å±‚ï¼‰
# 3.7GB åŸºç¡€å±‚ä»è¢« llama3:70b å¼•ç”¨

ollama rm llama3:70b
# é‡Šæ”¾ 36GBï¼ˆç‹¬æœ‰å±‚ï¼‰ + 3.7GBï¼ˆåŸºç¡€å±‚ï¼‰ = 39.7GB
\`\`\`

**å½±å“**:
- åˆ é™¤ç¡®è®¤å¯¹è¯æ¡†æ˜¾ç¤ºçš„"å°†é‡Šæ”¾çš„ç©ºé—´"æ˜¯**ä¼°ç®—å€¼**
- å®é™…é‡Šæ”¾çš„ç©ºé—´å¯èƒ½æ›´å°‘ï¼ˆå¦‚æœæœ‰å…±äº«å±‚ï¼‰
- UI æ–‡æ¡ˆéœ€è¦è¯´æ˜ï¼š"This will free up approximately X GB"

---

## 5. æŠ€æœ¯å†³ç­–æ±‡æ€»

### 5.1 å…³é”®å†³ç­–

| é¢†åŸŸ | å†³ç­– | ç†ç”± |
|------|------|------|
| **æµå¼ä¸‹è½½** | useMutation + React State | v4 ä¸æ”¯æŒæµå¼æ•°æ®ï¼Œéœ€æ‰‹åŠ¨ç®¡ç†è¿›åº¦ |
| **å¹¶å‘æ§åˆ¶** | p-queue (concurrency: 2) | æˆç†Ÿã€å¯é ï¼Œé¿å… Ollama è¿‡è½½ |
| **æš‚åœ/ç»§ç»­** | å–æ¶ˆåé‡æ–°å¼€å§‹ï¼ˆæ— æ–­ç‚¹ç»­ä¼ ï¼‰ | Ollama API ä¸æ”¯æŒ Range Requests |
| **ç£ç›˜æ£€æµ‹** | Node.js åŸç”Ÿ `statfs()` | v22 å®Œå…¨æ”¯æŒï¼Œæ— éœ€ç¬¬ä¸‰æ–¹åº“ |
| **æ¨¡å‹æ£€æµ‹** | æŸ¥è¯¢ SQLite æ•°æ®åº“ | å”¯ä¸€å¯é çš„æ•°æ®æºï¼ˆPrivate Modeï¼‰ |
| **åˆ é™¤å®‰å…¨** | å¤šå±‚æ£€æŸ¥ï¼ˆæ•°æ®åº“ + Ollamaï¼‰ | é˜²æ­¢åˆ é™¤æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹ |
| **Electron æ¶æ„** | Renderer ç›´æ¥è°ƒç”¨ Ollama API | ç®€å•ã€é«˜æ•ˆã€ä¸ç°æœ‰ä»£ç ä¸€è‡´ |

### 5.2 ä¾èµ–é¡¹

**éœ€è¦å®‰è£…**:
\`\`\`bash
npm install p-queue
\`\`\`

**å·²å­˜åœ¨**:
- `ollama@0.6.0`
- `@tanstack/react-query@4.29.14`
- `better-sqlite3@12.4.1`
- `drizzle-orm@0.44.6`

### 5.3 æ–‡ä»¶ç»“æ„

**æ–°å¢æ–‡ä»¶**:
\`\`\`
client/src/
â”œâ”€â”€ main/
â”‚   â”œâ”€â”€ ipc/
â”‚   â”‚   â”œâ”€â”€ disk-space-handlers.ts       # âœ¨ æ–°å¢
â”‚   â”‚   â””â”€â”€ model-handlers.ts            # âœ¨ æ–°å¢
â”‚   â””â”€â”€ local/
â”‚       â”œâ”€â”€ db/queries/
â”‚       â”‚   â””â”€â”€ models.ts                # âœ¨ æ–°å¢
â”‚       â””â”€â”€ services/
â”‚           â”œâ”€â”€ disk-space-manager.ts    # âœ¨ æ–°å¢
â”‚           â””â”€â”€ ollama-model-manager.ts  # âœ¨ æ–°å¢
â”‚
â””â”€â”€ renderer/src/
    â”œâ”€â”€ lib/
    â”‚   â””â”€â”€ ollama-client.ts             # ğŸ”„ æ‰©å±•
    â”‚
    â””â”€â”€ hooks/
        â”œâ”€â”€ ollama-models/
        â”‚   â”œâ”€â”€ queries/
        â”‚   â”‚   â”œâ”€â”€ useInstalledModels.ts    # âœ¨ æ–°å¢
        â”‚   â”‚   â””â”€â”€ useAvailableModels.ts    # âœ¨ æ–°å¢
        â”‚   â””â”€â”€ mutations/
        â”‚       â”œâ”€â”€ useDownloadModel.ts      # âœ¨ æ–°å¢
        â”‚       â””â”€â”€ useDeleteModel.ts        # âœ¨ æ–°å¢
        â”‚
        â””â”€â”€ mode/
            â”œâ”€â”€ useDiskSpace.ts              # âœ¨ æ–°å¢
            â””â”€â”€ useModelUsage.ts             # âœ¨ æ–°å¢
\`\`\`

---

## 6. é£é™©ä¸ç¼“è§£

### 6.1 å·²è¯†åˆ«é£é™©

| é£é™© | ä¸¥é‡ç¨‹åº¦ | ç¼“è§£æªæ–½ |
|------|---------|---------|
| Ollama æœåŠ¡æœªè¿è¡Œ | é«˜ | é›†æˆç°æœ‰çš„ OllamaManager æ£€æµ‹é€»è¾‘ |
| ç½‘ç»œä¸­æ–­å¯¼è‡´ä¸‹è½½å¤±è´¥ | ä¸­ | è‡ªåŠ¨é‡è¯• + ç”¨æˆ·æ‰‹åŠ¨é‡è¯•æŒ‰é’® |
| ç£ç›˜ç©ºé—´ä¸è¶³ | ä¸­ | ä¸‹è½½å‰æ£€æŸ¥ + å®æ—¶ç›‘æ§ |
| åˆ é™¤æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹ | é«˜ | å¤šå±‚æ£€æŸ¥ + ç”¨æˆ·ç¡®è®¤å¯¹è¯æ¡† |
| å¹¶å‘ä¸‹è½½è¿‡å¤š | ä½ | p-queue é™åˆ¶å¹¶å‘æ•°ä¸º 2 |
| æ¨¡å‹å…±äº«å±‚è¯¯åˆ  | ä½ | Ollama è‡ªåŠ¨ç®¡ç†ï¼Œæ— éœ€é¢å¤–å¤„ç† |

### 6.2 æ€§èƒ½è€ƒè™‘

**æŸ¥è¯¢é¢‘ç‡**:
- æ¨¡å‹åˆ—è¡¨ï¼šstaleTime 2 åˆ†é’Ÿï¼ŒæŒ‰éœ€å¤±æ•ˆ
- ç£ç›˜ç©ºé—´ï¼šstaleTime 30 ç§’ï¼Œæ¯åˆ†é’Ÿè‡ªåŠ¨åˆ·æ–°
- æ¨¡å‹ä½¿ç”¨ï¼šstaleTime 30 ç§’ï¼Œåˆ é™¤å‰å¼ºåˆ¶åˆ·æ–°

**å¹¶å‘é™åˆ¶**:
- æœ€å¤š 2 ä¸ªæ¨¡å‹åŒæ—¶ä¸‹è½½
- å…¶ä»–ä¸‹è½½ä»»åŠ¡æ’é˜Ÿç­‰å¾…
- é¿å… Ollama API è¿‡è½½

**ç¼“å­˜ç­–ç•¥**:
- ä¸‹è½½æˆåŠŸåå¤±æ•ˆ `['local-models']`
- åˆ é™¤æˆåŠŸåå¤±æ•ˆ `['local-models']`, `['disk-space']`, `['model-usage-stats']`

---

## 7. åç»­é˜¶æ®µ

### Phase 1: è®¾è®¡ï¼ˆä¸‹ä¸€æ­¥ï¼‰

1. ç”Ÿæˆ `data-model.md`ï¼šå®šä¹‰ LocalLLMModelã€DownloadTaskã€ModelConfig å®ä½“
2. ç”Ÿæˆ `contracts/ollama-api.yaml`ï¼šOllama API è§„èŒƒï¼ˆOpenAPI æ ¼å¼ï¼‰
3. ç”Ÿæˆ `quickstart.md`ï¼šå¼€å‘å¿«é€Ÿä¸Šæ‰‹æŒ‡å—
4. æ›´æ–° Agent Contextï¼šè¿è¡Œ `.specify/scripts/bash/update-agent-context.sh claude`

### Phase 2: ä»»åŠ¡åˆ†è§£

è¿è¡Œ `/speckit.tasks` ç”Ÿæˆè¯¦ç»†çš„å¼€å‘ä»»åŠ¡æ¸…å•ã€‚

---

**ç ”ç©¶å®Œæˆæ—¶é—´**: 2025-10-23  
**ä¸‹ä¸€æ­¥**: Phase 1 - è®¾è®¡ä¸å¥‘çº¦ç”Ÿæˆ
